\begin{abstract}

    \iffalse
\begin{enumerate}
    \item Summarize key objectives, methodology, findings, and significance.
    \item Keep it brief and enticing for readers to explore the full content.
\end{enumerate}
\fi

In recent years, the  proliferation of data poisoning has emerged as a significant concern, casting a formidable shadow over the security of machine learning models. Over the past decade, we have witnessed a substantial increase in malicious poisoning attacks aimed at compromising the integrity of machine learning models. In our extensive experiments, we conducted a thorough evaluation of contrastive learning frameworks, specifically MoCo and SimCLR, using both clean and perturbed versions of the CIFAR-10 dataset with the intention of determining the most important aspects of a model that might contribute to its robustness against adversarial poisoning, specifically focusing on variations in data augmentation methods, encoders, and loss functions. Our findings, however, indicate that there is not a statistically significant difference in performance degradation between the two models. This suggests that the impact of these factors on contrastive learning may either be inconsequential or more intricate than initially presumed. 

For reference, our code is available at : \url{https://github.com/anthonyjholmes1/com-sci-260D-Fall23}

Keywords: Contrastive Learning, Self-Supervised Learning, Data Poisoning, Robustness, Core-Set Selection, Poisoning Attacks.
\end{abstract}