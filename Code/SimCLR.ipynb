{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVphmKTiPagR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "\n",
        "class CIFAR10Pair(CIFAR10):\n",
        "    \"\"\"CIFAR10 Dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            pos_1 = self.transform(img)\n",
        "            pos_2 = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return pos_1, pos_2, target\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models.resnet import resnet50\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, feature_dim=128):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.f = []\n",
        "        for name, module in resnet50().named_children():\n",
        "            if name == 'conv1':\n",
        "                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n",
        "                self.f.append(module)\n",
        "        # encoder\n",
        "        self.f = nn.Sequential(*self.f)\n",
        "        # projection head\n",
        "        self.g = nn.Sequential(nn.Linear(2048, 512, bias=False), nn.BatchNorm1d(512),\n",
        "                               nn.ReLU(inplace=True), nn.Linear(512, feature_dim, bias=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.f(x)\n",
        "        feature = torch.flatten(x, start_dim=1)\n",
        "        out = self.g(feature)\n",
        "        return F.normalize(feature, dim=-1), F.normalize(out, dim=-1)"
      ],
      "metadata": {
        "id": "48L1V0igP2H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from thop import profile, clever_format\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# train for one epoch to learn unique features\n",
        "def train(net, data_loader, train_optimizer):\n",
        "    net.train()\n",
        "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
        "    for pos_1, pos_2, target in train_bar:\n",
        "        pos_1, pos_2 = pos_1.cuda(non_blocking=True), pos_2.cuda(non_blocking=True)\n",
        "        feature_1, out_1 = net(pos_1)\n",
        "        feature_2, out_2 = net(pos_2)\n",
        "        # [2*B, D]\n",
        "        out = torch.cat([out_1, out_2], dim=0)\n",
        "        # [2*B, 2*B]\n",
        "        sim_matrix = torch.exp(torch.mm(out, out.t().contiguous()) / temperature)\n",
        "        mask = (torch.ones_like(sim_matrix) - torch.eye(2 * batch_size, device=sim_matrix.device)).bool()\n",
        "        # [2*B, 2*B-1]\n",
        "        sim_matrix = sim_matrix.masked_select(mask).view(2 * batch_size, -1)\n",
        "\n",
        "        # compute loss\n",
        "        pos_sim = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
        "        # [2*B]\n",
        "        pos_sim = torch.cat([pos_sim, pos_sim], dim=0)\n",
        "        loss = (- torch.log(pos_sim / sim_matrix.sum(dim=-1))).mean()\n",
        "        train_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_optimizer.step()\n",
        "\n",
        "        total_num += batch_size\n",
        "        total_loss += loss.item() * batch_size\n",
        "        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n",
        "\n",
        "    return total_loss / total_num\n",
        "\n",
        "\n",
        "# test for one epoch, use weighted knn to find the most similar images' label to assign the test image\n",
        "def test(net, memory_data_loader, test_data_loader):\n",
        "    net.eval()\n",
        "    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
        "    with torch.no_grad():\n",
        "        # generate feature bank\n",
        "        for data, _, target in tqdm(memory_data_loader, desc='Feature extracting'):\n",
        "            feature, out = net(data.cuda(non_blocking=True))\n",
        "            feature_bank.append(feature)\n",
        "        # [D, N]\n",
        "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
        "        # [N]\n",
        "        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n",
        "        # loop test data to predict the label by weighted knn search\n",
        "        test_bar = tqdm(test_data_loader)\n",
        "        for data, _, target in test_bar:\n",
        "            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n",
        "            feature, out = net(data)\n",
        "\n",
        "            total_num += data.size(0)\n",
        "            # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
        "            sim_matrix = torch.mm(feature, feature_bank)\n",
        "            # [B, K]\n",
        "            sim_weight, sim_indices = sim_matrix.topk(k=k, dim=-1)\n",
        "            # [B, K]\n",
        "            sim_labels = torch.gather(feature_labels.expand(data.size(0), -1), dim=-1, index=sim_indices)\n",
        "            sim_weight = (sim_weight / temperature).exp()\n",
        "\n",
        "            # counts for each class\n",
        "            one_hot_label = torch.zeros(data.size(0) * k, c, device=sim_labels.device)\n",
        "            # [B*K, C]\n",
        "            one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
        "            # weighted score ---> [B, C]\n",
        "            pred_scores = torch.sum(one_hot_label.view(data.size(0), -1, c) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
        "\n",
        "            pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
        "            total_top1 += torch.sum((pred_labels[:, :1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
        "            total_top5 += torch.sum((pred_labels[:, :5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
        "            test_bar.set_description('Test Epoch: [{}/{}] Acc@1:{:.2f}% Acc@5:{:.2f}%'\n",
        "                                     .format(epoch, epochs, total_top1 / total_num * 100, total_top5 / total_num * 100))\n",
        "\n",
        "    return total_top1 / total_num * 100, total_top5 / total_num * 100\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Train SimCLR')\n",
        "    parser.add_argument('--feature_dim', default=128, type=int, help='Feature dim for latent vector')\n",
        "    parser.add_argument('--temperature', default=0.5, type=float, help='Temperature used in softmax')\n",
        "    parser.add_argument('--k', default=200, type=int, help='Top k most similar images used to predict the label')\n",
        "    parser.add_argument('--batch_size', default=128, type=int, help='Number of images in each mini-batch')\n",
        "    parser.add_argument('--epochs', default=50, type=int, help='Number of sweeps over the dataset to train')\n",
        "\n",
        "    # args parse\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    feature_dim, temperature, k = args.feature_dim, args.temperature, args.k\n",
        "    batch_size, epochs = args.batch_size, args.epochs\n",
        "\n",
        "    # data prepare\n",
        "    train_data = CIFAR10Pair(root='data', train=True, transform=train_transform, download=True)\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True,\n",
        "                              drop_last=True)\n",
        "    memory_data = CIFAR10Pair(root='data', train=True, transform=test_transform, download=True)\n",
        "    memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
        "    test_data = CIFAR10Pair(root='data', train=False, transform=test_transform, download=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
        "\n",
        "    # model setup and optimizer config\n",
        "    model = Model(feature_dim).cuda()\n",
        "    flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32).cuda(),))\n",
        "    flops, params = clever_format([flops, params])\n",
        "    print('# Model Params: {} FLOPs: {}'.format(params, flops))\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "    c = len(memory_data.classes)\n",
        "\n",
        "    # training loop\n",
        "    results = {'train_loss': [], 'test_acc@1': [], 'test_acc@5': []}\n",
        "    save_name_pre = '{}_{}_{}_{}_{}'.format(feature_dim, temperature, k, batch_size, epochs)\n",
        "    if not os.path.exists('results'):\n",
        "        os.mkdir('results')\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, train_loader, optimizer)\n",
        "        results['train_loss'].append(train_loss)\n",
        "        test_acc_1, test_acc_5 = test(model, memory_loader, test_loader)\n",
        "        results['test_acc@1'].append(test_acc_1)\n",
        "        results['test_acc@5'].append(test_acc_5)\n",
        "        # save statistics\n",
        "        data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))\n",
        "        data_frame.to_csv('results/{}_statistics.csv'.format(save_name_pre), index_label='epoch')\n",
        "        if test_acc_1 > best_acc:\n",
        "            best_acc = test_acc_1\n",
        "            torch.save(model.state_dict(), 'results/{}_model.pth'.format(save_name_pre))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4bdUM8uP6zV",
        "outputId": "f4e2c5ba-a97b-480c-bbe1-6ccf4a8e00d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
            "# Model Params: 24.62M FLOPs: 1.31G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: [1/50] Loss: 4.8410: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.94it/s]\n",
            "Test Epoch: [1/50] Acc@1:41.04% Acc@5:89.45%: 100%|██████████| 79/79 [00:12<00:00,  6.57it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [2/50] Loss: 4.5625: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.72it/s]\n",
            "Test Epoch: [2/50] Acc@1:45.20% Acc@5:91.64%: 100%|██████████| 79/79 [00:11<00:00,  6.73it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [3/50] Loss: 4.4493: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.94it/s]\n",
            "Test Epoch: [3/50] Acc@1:47.79% Acc@5:92.38%: 100%|██████████| 79/79 [00:11<00:00,  6.61it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [4/50] Loss: 4.3823: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.75it/s]\n",
            "Test Epoch: [4/50] Acc@1:51.01% Acc@5:93.98%: 100%|██████████| 79/79 [00:12<00:00,  6.27it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [5/50] Loss: 4.3302: 100%|██████████| 390/390 [05:08<00:00,  1.26it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.83it/s]\n",
            "Test Epoch: [5/50] Acc@1:53.44% Acc@5:94.65%: 100%|██████████| 79/79 [00:12<00:00,  6.34it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [6/50] Loss: 4.2924: 100%|██████████| 390/390 [05:08<00:00,  1.26it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:46<00:00,  8.48it/s]\n",
            "Test Epoch: [6/50] Acc@1:55.89% Acc@5:95.62%: 100%|██████████| 79/79 [00:12<00:00,  6.50it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [7/50] Loss: 4.2605: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.80it/s]\n",
            "Test Epoch: [7/50] Acc@1:57.96% Acc@5:96.24%: 100%|██████████| 79/79 [00:11<00:00,  6.84it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [8/50] Loss: 4.2468: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:45<00:00,  8.56it/s]\n",
            "Test Epoch: [8/50] Acc@1:59.30% Acc@5:96.21%: 100%|██████████| 79/79 [00:12<00:00,  6.26it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [9/50] Loss: 4.2297: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.91it/s]\n",
            "Test Epoch: [9/50] Acc@1:61.20% Acc@5:96.60%: 100%|██████████| 79/79 [00:11<00:00,  6.91it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [10/50] Loss: 4.2164: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.79it/s]\n",
            "Test Epoch: [10/50] Acc@1:60.82% Acc@5:96.84%: 100%|██████████| 79/79 [00:12<00:00,  6.46it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [11/50] Loss: 4.2000: 100%|██████████| 390/390 [05:08<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.80it/s]\n",
            "Test Epoch: [11/50] Acc@1:62.78% Acc@5:97.11%: 100%|██████████| 79/79 [00:12<00:00,  6.38it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [12/50] Loss: 4.1916: 100%|██████████| 390/390 [05:08<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.80it/s]\n",
            "Test Epoch: [12/50] Acc@1:63.15% Acc@5:97.18%: 100%|██████████| 79/79 [00:12<00:00,  6.57it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [13/50] Loss: 4.1786: 100%|██████████| 390/390 [05:08<00:00,  1.26it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.80it/s]\n",
            "Test Epoch: [13/50] Acc@1:63.81% Acc@5:97.30%: 100%|██████████| 79/79 [00:11<00:00,  6.79it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [14/50] Loss: 4.1729: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.86it/s]\n",
            "Test Epoch: [14/50] Acc@1:65.46% Acc@5:97.43%: 100%|██████████| 79/79 [00:12<00:00,  6.36it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [15/50] Loss: 4.1638: 100%|██████████| 390/390 [05:08<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.73it/s]\n",
            "Test Epoch: [15/50] Acc@1:65.34% Acc@5:97.69%: 100%|██████████| 79/79 [00:12<00:00,  6.18it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [16/50] Loss: 4.1561: 100%|██████████| 390/390 [05:08<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.95it/s]\n",
            "Test Epoch: [16/50] Acc@1:65.91% Acc@5:97.52%: 100%|██████████| 79/79 [00:11<00:00,  6.72it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [17/50] Loss: 4.1480: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.79it/s]\n",
            "Test Epoch: [17/50] Acc@1:67.04% Acc@5:97.70%: 100%|██████████| 79/79 [00:12<00:00,  6.30it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [18/50] Loss: 4.1465: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.92it/s]\n",
            "Test Epoch: [18/50] Acc@1:66.69% Acc@5:97.72%: 100%|██████████| 79/79 [00:11<00:00,  6.77it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [19/50] Loss: 4.1419: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.79it/s]\n",
            "Test Epoch: [19/50] Acc@1:67.23% Acc@5:97.89%: 100%|██████████| 79/79 [00:12<00:00,  6.25it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [20/50] Loss: 4.1321: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.87it/s]\n",
            "Test Epoch: [20/50] Acc@1:67.44% Acc@5:97.73%: 100%|██████████| 79/79 [00:12<00:00,  6.54it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [21/50] Loss: 4.1327: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.92it/s]\n",
            "Test Epoch: [21/50] Acc@1:68.09% Acc@5:97.87%: 100%|██████████| 79/79 [00:11<00:00,  6.70it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [22/50] Loss: 4.1252: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.87it/s]\n",
            "Test Epoch: [22/50] Acc@1:68.50% Acc@5:97.95%: 100%|██████████| 79/79 [00:11<00:00,  6.79it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [23/50] Loss: 4.1220: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.97it/s]\n",
            "Test Epoch: [23/50] Acc@1:68.63% Acc@5:97.90%: 100%|██████████| 79/79 [00:11<00:00,  6.85it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [24/50] Loss: 4.1182: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.92it/s]\n",
            "Test Epoch: [24/50] Acc@1:68.59% Acc@5:97.91%: 100%|██████████| 79/79 [00:11<00:00,  6.74it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [25/50] Loss: 4.1147: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.86it/s]\n",
            "Test Epoch: [25/50] Acc@1:69.18% Acc@5:98.08%: 100%|██████████| 79/79 [00:11<00:00,  6.72it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [26/50] Loss: 4.1115: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.73it/s]\n",
            "Test Epoch: [26/50] Acc@1:69.39% Acc@5:97.87%: 100%|██████████| 79/79 [00:11<00:00,  6.81it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [27/50] Loss: 4.1055: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.91it/s]\n",
            "Test Epoch: [27/50] Acc@1:69.93% Acc@5:97.99%: 100%|██████████| 79/79 [00:11<00:00,  6.80it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [28/50] Loss: 4.1047: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.77it/s]\n",
            "Test Epoch: [28/50] Acc@1:69.65% Acc@5:98.06%: 100%|██████████| 79/79 [00:12<00:00,  6.22it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [29/50] Loss: 4.1003: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.98it/s]\n",
            "Test Epoch: [29/50] Acc@1:69.96% Acc@5:98.17%: 100%|██████████| 79/79 [00:11<00:00,  6.79it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [30/50] Loss: 4.0987: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.90it/s]\n",
            "Test Epoch: [30/50] Acc@1:70.71% Acc@5:98.17%: 100%|██████████| 79/79 [00:12<00:00,  6.54it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [31/50] Loss: 4.0960: 100%|██████████| 390/390 [05:10<00:00,  1.26it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.77it/s]\n",
            "Test Epoch: [31/50] Acc@1:70.23% Acc@5:97.95%: 100%|██████████| 79/79 [00:12<00:00,  6.35it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [32/50] Loss: 4.0876: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.92it/s]\n",
            "Test Epoch: [32/50] Acc@1:70.71% Acc@5:98.12%: 100%|██████████| 79/79 [00:11<00:00,  6.73it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [33/50] Loss: 4.0911: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:45<00:00,  8.63it/s]\n",
            "Test Epoch: [33/50] Acc@1:71.44% Acc@5:98.18%: 100%|██████████| 79/79 [00:12<00:00,  6.56it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [34/50] Loss: 4.0856: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.79it/s]\n",
            "Test Epoch: [34/50] Acc@1:71.18% Acc@5:98.26%: 100%|██████████| 79/79 [00:12<00:00,  6.33it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [35/50] Loss: 4.0851: 100%|██████████| 390/390 [05:10<00:00,  1.26it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.97it/s]\n",
            "Test Epoch: [35/50] Acc@1:71.42% Acc@5:98.30%: 100%|██████████| 79/79 [00:11<00:00,  6.69it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [36/50] Loss: 4.0777: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:45<00:00,  8.66it/s]\n",
            "Test Epoch: [36/50] Acc@1:71.26% Acc@5:98.31%: 100%|██████████| 79/79 [00:12<00:00,  6.42it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [37/50] Loss: 4.0764: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.94it/s]\n",
            "Test Epoch: [37/50] Acc@1:71.70% Acc@5:98.26%: 100%|██████████| 79/79 [00:12<00:00,  6.33it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [38/50] Loss: 4.0737: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:45<00:00,  8.68it/s]\n",
            "Test Epoch: [38/50] Acc@1:72.44% Acc@5:98.48%: 100%|██████████| 79/79 [00:11<00:00,  6.77it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [39/50] Loss: 4.0723: 100%|██████████| 390/390 [05:05<00:00,  1.28it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:45<00:00,  8.53it/s]\n",
            "Test Epoch: [39/50] Acc@1:72.30% Acc@5:98.24%: 100%|██████████| 79/79 [00:11<00:00,  6.63it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [40/50] Loss: 4.0757: 100%|██████████| 390/390 [05:05<00:00,  1.28it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.72it/s]\n",
            "Test Epoch: [40/50] Acc@1:72.02% Acc@5:98.35%: 100%|██████████| 79/79 [00:12<00:00,  6.24it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [41/50] Loss: 4.0662: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.96it/s]\n",
            "Test Epoch: [41/50] Acc@1:72.02% Acc@5:98.58%: 100%|██████████| 79/79 [00:11<00:00,  6.82it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [42/50] Loss: 4.0655: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.79it/s]\n",
            "Test Epoch: [42/50] Acc@1:72.30% Acc@5:98.49%: 100%|██████████| 79/79 [00:11<00:00,  6.71it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [43/50] Loss: 4.0625: 100%|██████████| 390/390 [05:05<00:00,  1.28it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.73it/s]\n",
            "Test Epoch: [43/50] Acc@1:72.99% Acc@5:98.48%: 100%|██████████| 79/79 [00:11<00:00,  6.59it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [44/50] Loss: 4.0614: 100%|██████████| 390/390 [05:05<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:45<00:00,  8.67it/s]\n",
            "Test Epoch: [44/50] Acc@1:73.20% Acc@5:98.46%: 100%|██████████| 79/79 [00:11<00:00,  6.60it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [45/50] Loss: 4.0615: 100%|██████████| 390/390 [05:05<00:00,  1.28it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.83it/s]\n",
            "Test Epoch: [45/50] Acc@1:73.31% Acc@5:98.47%: 100%|██████████| 79/79 [00:12<00:00,  6.28it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [46/50] Loss: 4.0593: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.84it/s]\n",
            "Test Epoch: [46/50] Acc@1:73.73% Acc@5:98.60%: 100%|██████████| 79/79 [00:11<00:00,  6.77it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [47/50] Loss: 4.0563: 100%|██████████| 390/390 [05:04<00:00,  1.28it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.85it/s]\n",
            "Test Epoch: [47/50] Acc@1:72.88% Acc@5:98.44%: 100%|██████████| 79/79 [00:11<00:00,  6.72it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [48/50] Loss: 4.0603: 100%|██████████| 390/390 [05:05<00:00,  1.28it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.82it/s]\n",
            "Test Epoch: [48/50] Acc@1:73.64% Acc@5:98.64%: 100%|██████████| 79/79 [00:12<00:00,  6.25it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [49/50] Loss: 4.0552: 100%|██████████| 390/390 [05:06<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:44<00:00,  8.81it/s]\n",
            "Test Epoch: [49/50] Acc@1:74.33% Acc@5:98.64%: 100%|██████████| 79/79 [00:12<00:00,  6.27it/s]\n",
            "  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train Epoch: [50/50] Loss: 4.0494: 100%|██████████| 390/390 [05:07<00:00,  1.27it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:43<00:00,  8.95it/s]\n",
            "Test Epoch: [50/50] Acc@1:74.10% Acc@5:98.63%: 100%|██████████| 79/79 [00:12<00:00,  6.20it/s]\n"
          ]
        }
      ]
    }
  ]
}