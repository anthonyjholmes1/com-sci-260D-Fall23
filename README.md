#COM SCI 260D Large Scale Machine Learning

## Description

In recent times, the proliferation of data poisoning has emerged as a critical societal issue, casting a formidable shadow over the security of machine learning models. 
Over the past decade, we have witnessed a substantial surge in malicious poisoning attacks aimed at subverting the integrity of machine learning models.
In this paper, we shall embark upon an extensive examination of the repertoire of tools at our disposal for countering data poisoning attacks within the framework of Contrastive Learning with SAS. Our investigation will delve into the comparative effectiveness of these tools, providing insights into which among them yields the most robust defenses, all while elucidating the underlying rationales for their efficacy.

## Authors
- Anthony Holmes
- Adithya Embar
- Dylan Gunn
- Mohammad Akbarnezhad

## Model Sources

| Model | Link |
| ----- | ---- |
| MoCo | [link](https://colab.research.google.com/github/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb) |
| SimCLR | [link](https://github.com/leftthomas/SimCLR?tab=readme-ov-file) | 
